{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NhONssvJwRqx",
        "outputId": "5930be12-cc21-47a8-e6f9-73bebbaf2a1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "r33Gog5SwUYn",
        "outputId": "c1e4b288-e349-4630-8fc9-37c288cb951b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  vgg16_cats_dogs.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/data-20251027T075134Z-1-001\n",
        "! ls"
      ],
      "metadata": {
        "id": "tHMDzmrpwUOi",
        "outputId": "d7c2ee86-ca86-4f68-d18a-ba6a4f1ead29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data-20251027T075134Z-1-001\n",
            "data  vgg16_cats_dogs.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÂåØÂÖ•Â•ó‰ª∂\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# Ë≥áÊñôË∑ØÂæë\n",
        "train_dir = '/content/drive/MyDrive/data-20251027T075134Z-1-001'  # Â∫ï‰∏ãË¶ÅÊúâ /cats, /dogs Ë≥áÊñôÂ§æ\n",
        "val_dir = '/content/drive/MyDrive/data-20251027T075134Z-1-001'\n",
        "\n",
        "# ÂΩ±ÂÉèÈ†êËôïÁêÜÔºöË≥áÊñôÂ¢ûÂº∑\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Âª∫Á´ãË≥áÊñôÁîüÊàêÂô®\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# ËºâÂÖ• VGG16 Ê®°Âûã (‰∏çÂåÖÂê´È†ÇÂ±§ÂÖ®ÈÄ£Êé•Â±§)\n",
        "base_model = VGG16(weights='imagenet',\n",
        "                   include_top=False,\n",
        "                   input_shape=(150, 150, 3))\n",
        "\n",
        "# ÂáçÁµêÈ†êË®ìÁ∑¥Ê¨äÈáçÔºà‰∏çË®ìÁ∑¥ VGG16 Êú¨È´îÔºâ\n",
        "base_model.trainable = False\n",
        "\n",
        "# Âª∫Á´ãÊñ∞Ê®°Âûã\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')  # ÂÖ©È°ûÔºöË≤ì / Áãó\n",
        "])\n",
        "\n",
        "# Á∑®Ë≠ØÊ®°Âûã\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Ë®ìÁ∑¥Ê®°Âûã\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "# ÂÑ≤Â≠òÊ®°Âûã\n",
        "model.save('cat_dog_vgg16.h5')"
      ],
      "metadata": {
        "id": "MqzmjJjixDsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dddbfff-7b5a-46d5-e0d2-f40b7ac3a87a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 125 images belonging to 1 classes.\n",
            "Found 125 images belonging to 1 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 18s/step - accuracy: 0.5551 - loss: 0.7865 - val_accuracy: 1.0000 - val_loss: 0.0155\n",
            "Epoch 2/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 22s/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 3/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 2.3807e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 21s/step - accuracy: 1.0000 - loss: 3.3052e-04 - val_accuracy: 1.0000 - val_loss: 9.3492e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 9.9278e-05 - val_accuracy: 1.0000 - val_loss: 5.0782e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 4.1676e-05 - val_accuracy: 1.0000 - val_loss: 3.3703e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 3.4133e-05 - val_accuracy: 1.0000 - val_loss: 2.5361e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 2.9138e-05 - val_accuracy: 1.0000 - val_loss: 2.0718e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 3.3479e-05 - val_accuracy: 1.0000 - val_loss: 1.7924e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 1.9043e-05 - val_accuracy: 1.0000 - val_loss: 1.5984e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ËºâÂÖ•Ë®ìÁ∑¥Â•ΩÁöÑÊ®°Âûã\n",
        "model = load_model('cat_dog_vgg16.h5')\n",
        "\n",
        "# Ê∏¨Ë©¶Ë≥áÊñôÂ§æË∑ØÂæë\n",
        "test_dir = '/content/drive/MyDrive/data-20251027T075134Z-1-001/data'\n",
        "\n",
        "# È†êÊ∏¨ÁµêÊûúËº∏Âá∫\n",
        "for filename in os.listdir(test_dir):\n",
        "    if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "        img_path = os.path.join(test_dir, filename)\n",
        "\n",
        "        # ËÆÄÂèñÂúñÁâá‰∏¶Ë™øÊï¥Â∞∫ÂØ∏\n",
        "        img = image.load_img(img_path, target_size=(150, 150))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Â¢ûÂä†ÊâπÊ¨°Á∂≠Â∫¶\n",
        "        img_array /= 255.0  # Ê≠£Ë¶èÂåñ\n",
        "\n",
        "        # È†êÊ∏¨\n",
        "        prediction = model.predict(img_array)\n",
        "        if prediction[0][0] > 0.5:\n",
        "            label = 'Dog üê∂'\n",
        "        else:\n",
        "            label = 'Cat üê±'\n",
        "\n",
        "        print(f\"{filename} -> {label} ({prediction[0][0]:.4f})\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-EUjvqA15Vo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "764c67c3-c7fd-4852-f741-15c826f6e4a9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step\n",
            "lenet5_model_structure.png -> Cat üê± (0.0015)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
            "cat.jpg -> Cat üê± (0.0000)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
            "dog.jpg -> Cat üê± (0.0000)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}